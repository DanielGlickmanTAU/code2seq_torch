# @package _global_
defaults:
  - model: code2seq

seed: 7
num_workers: 2
log_offline: false

# data keys
data_folder: data
vocabulary_name: vocabulary.pkl
train_holdout: train
val_holdout: val
test_holdout: test

save_every_epoch: 1
val_every_epoch: 1
log_every_epoch: 10

hyper_parameters:
  n_epochs: 3000
  patience: 10
  batch_size: 512
  test_batch_size: 512
  clip_norm: 5
  max_context: 200
  random_context: true
  shuffle_data: true

  optimizer: "Momentum"
  nesterov: true
  learning_rate: 0.01
  weight_decay: 0
  decay_gamma: 0.95
